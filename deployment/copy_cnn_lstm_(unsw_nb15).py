# -*- coding: utf-8 -*-
"""copy cnn-lstm_(UNSW-NB15).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JRDBxNIm0y-wuAvXD18JFO3huXNgQfmw

# Installing initial dependencies
"""

from google.colab import drive
drive.mount('/content/drive')


!pip install tensorflow scikit-learn imbalanced-learn shap pandas numpy matplotlib seaborn

"""# Import libraries"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import make_pipeline
from sklearn.utils.class_weight import compute_class_weight

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Reshape, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2

"""# Implementation of (UNSW-NB15 Dataset)"""

# Load UNSW-NB15 Dataset
nb15 = "/content/drive/MyDrive/Data_Anaylsis/NF-UNSW-NB15-v2.csv"
nb15_df = pd.read_csv(nb15)

# Preprocessing
# Preprocessing for UNSW-NB15
def preprocess_unsw(df):
    # Clean column names by stripping whitespace
    df.columns = df.columns.str.strip()

    # Print columns after stripping whitespace to diagnose KeyError
    print("Columns after stripping whitespace:", df.columns.tolist())

    # Create binary label (normal=0, attack=1)
    # Corrected column name from 'label' to 'Label'
    df['Label'] = df['Label'].apply(lambda x: 0 if x == 0 else 1)

    # Remove infinite values and NaNs
    df = df.replace([np.inf, -np.inf], np.nan).dropna()

    # Feature selection - Use features actually available in the dataframe
    # Based on the printed columns, select relevant features
    available_cols = df.columns.tolist()
    initial_features = [
        'PROTOCOL', 'L7_PROTO', 'IN_BYTES', 'IN_PKTS', 'OUT_BYTES', 'OUT_PKTS',
        'FLOW_DURATION_MILLISECONDS', 'DURATION_IN', 'DURATION_OUT', 'MIN_TTL',
        'MAX_TTL', 'LONGEST_FLOW_PKT', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN',
        'MAX_IP_PKT_LEN', 'SRC_TO_DST_SECOND_BYTES', 'DST_TO_SRC_SECOND_BYTES',
        'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS', 'RETRANSMITTED_OUT_BYTES',
        'RETRANSMITTED_OUT_PKTS', 'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',
        'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES', 'NUM_PKTS_256_TO_512_BYTES',
        'NUM_PKTS_512_TO_1024_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN',
        'TCP_WIN_MAX_OUT', 'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID',
        'DNS_QUERY_TYPE', 'DNS_TTL_ANSWER', 'FTP_COMMAND_RET_CODE'
    ]

    available_features = [f for f in initial_features if f in available_cols]
    print(f"Using {len(available_features)} of {len(initial_features)} selected features")
    print("Available selected features:", available_features)


    # Define categorical and numerical features based on the available selected features
    cat_features = ['PROTOCOL']
    num_features = [f for f in available_features if f not in cat_features]

    print("Categorical features:", cat_features)
    print("Numerical features:", num_features)

    # One-hot encode categorical features
    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoded_cats = encoder.fit_transform(df[cat_features])

    # Scale numerical features
    scaler = StandardScaler()
    scaled_nums = scaler.fit_transform(df[num_features])

    # Combine features
    X = np.concatenate([encoded_cats, scaled_nums], axis=1)
    # Corrected column name from 'label' to 'Label'
    y = df['Label'].values

    return X, y, encoder, scaler, num_features

# Apply preprocessing
X_unsw, y_unsw, unsw_encoder, unsw_scaler, num_features = preprocess_unsw(nb15_df)

# Split and balance data
X_train_unsw, X_test_unsw, y_train_unsw, y_test_unsw = train_test_split(
    X_unsw, y_unsw, test_size=0.3, stratify=y_unsw, random_state=42
)

# Resample training data using SMOTE
sampler = SMOTE(random_state=42)
X_res_unsw, y_res_unsw = sampler.fit_resample(X_train_unsw, y_train_unsw)
print(f"Resampled training data shape: {X_res_unsw.shape}")

# Reshape for CNN-LSTM
X_train_unsw_3d = X_res_unsw.reshape((X_res_unsw.shape[0], X_res_unsw.shape[1], 1))
X_test_unsw_3d = X_test_unsw.reshape((X_test_unsw.shape[0], X_test_unsw.shape[1], 1))
print(f"3D Training shape: {X_train_unsw_3d.shape}")
print(f"3D Testing shape: {X_test_unsw_3d.shape}")

# Class imbalance handling
from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight('balanced', classes=np.unique(y_train_unsw), y=y_train_unsw)
class_weight_dict = dict(enumerate(class_weights))

print("Data preprocessing complete!")
print("\n")
print(f"Training shape: {X_train_unsw_3d.shape}, Test shape: {X_test_unsw_3d.shape}")
print(f"Class weights: {class_weight_dict}")
print("\n")

print("Dataset shape:", nb15_df.shape)
nb15_df.head(10)

from google.colab import drive
drive.mount('/content/drive')

"""# Hybrid CNN-LSTM Architecture"""

model = Sequential(name="CNN_LSTM_IDS")

# Input reshaping for time-series like data
model.add(Reshape((X_train_unsw_3d.shape[1], 1), input_shape=(X_train_unsw_3d.shape[1],)))

# CNN Feature Extraction
model.add(Conv1D(64, kernel_size=3, activation='relu', padding='same'))
model.add(MaxPooling1D(pool_size=2))
model.add(Dropout(0.3))

# LSTM Temporal Analysis
model.add(LSTM(100, return_sequences=True))
model.add(LSTM(50))
model.add(Dropout(0.3))

# Classification Head
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
)
model.summary()

"""# Training Configuration"""

# Train-test split
# X_train, X_test, y_train, y_test = train_test_split(
#     X_processed, y, test_size=0.2, stratify=y, random_state=42
# )



'''# Training parameters
batch_size = 128
epochs = 15

# Train with early stopping
history = model.fit(
    X_train_3d, y_train,
    batch_size=batch_size,
    epochs=epochs,
    validation_split=0.1,
    class_weight=class_weight_dict,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)
    ]
) '''

# Training Parameters
input_shape = (X_train_unsw_3d.shape[1], 1)
batch_size = 256  # Increased for efficiency
epochs = 15
validation_split = 0.15

# Callbacks
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

# Train the model
print("\nStarting model training...")
history = model.fit(
    X_train_unsw_3d,
    y_res_unsw,  # Corrected y_train to y_res_unsw
    batch_size=batch_size,
    epochs=epochs,
    validation_split=validation_split,
    class_weight=class_weight_dict,
    callbacks=[early_stopping],
    verbose=1
)

model.save("/content/drive/MyDrive/Data_Anaylsis/model/cnn_lstm_UNSW-NB15_model.h5")
print("Model saved as cnn_lstm_UNSW-NB15_model.h5")

"""# Evaluation & Visualization"""

# Performance metrics
y_pred_proba = model.predict(X_test_unsw_3d)
y_pred = (y_pred_proba > 0.5).astype(int)
print(classification_report(y_test_unsw, y_pred))

# Confusion Matrix (3.7.1-3.7.4)
plt.figure(figsize=(6, 4))
cm = confusion_matrix(y_test_unsw, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Normal', 'Attack'],
            yticklabels=['Normal', 'Attack'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

'''# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()'''

# Calculate metrics
accuracy = accuracy_score(y_test_unsw, y_pred)
precision = precision_score(y_test_unsw, y_pred)
recall = recall_score(y_test_unsw, y_pred)
f1 = f1_score(y_test_unsw, y_pred)
roc_auc = roc_auc_score(y_test_unsw, y_pred_proba)

# Print metrics
print("\n=== CLASSIFICATION REPORT ===")
print(f"Accuracy:    {accuracy:.4f}")
print(f"Precision:   {precision:.4f}")
print(f"Recall:      {recall:.4f}")
print(f"F1 Score:    {f1:.4f}")
print(f"ROC AUC:     {roc_auc:.4f}")

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test_unsw, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# ROC Curve
'''fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend()
plt.show()'''

# Accuracy plot
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss plot
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""# Explainability with SHAP"""

import shap

# Create explainer
# Use KernelExplainer as DeepExplainer might have compatibility issues
# with the custom model architecture and TensorFlow version.
# KernelExplainer requires a background dataset to estimate the expectation.
# A small, representative sample of the training data is suitable.
background = X_train_unsw_3d[np.random.choice(X_train_unsw_3d.shape[0], 100, replace=False)]

# For KernelExplainer, the predict function should accept a 2D array
# and return the model's output for the positive class (attack=1).
# We need to reshape the input back to 3D inside the predict function.
def model_predict(x):
    # Reshape the input to the model's expected 3D shape (samples, features, 1)
    x_3d = x.reshape(x.shape[0], x.shape[1], 1)
    # Return the probability of the positive class (attack=1)
    return model.predict(x_3d)[:, 0]

explainer = shap.KernelExplainer(model_predict, background.reshape(background.shape[0], background.shape[1]))

# Explain 10 samples
# KernelExplainer expects a 2D array for the samples to explain
shap_values = explainer.shap_values(X_test_unsw_3d[:10].reshape(10, X_test_unsw_3d.shape[1]))

# The feature names need to match the order of features in X_processed
# Using the num_features list from preprocessing
feature_names_list = unsw_encoder.get_feature_names_out().tolist() + num_features
shap.summary_plot(
    shap_values,
    X_test_unsw_3d[:10].reshape(10, X_test_unsw_3d.shape[1]),
    feature_names=feature_names_list
)

"""# Explainability with (LIME for local explanations)"""

import lime
import lime.lime_tabular

# Create LIME explainer
# Use the original 2D training data for LimeTabularExplainer
explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_train_unsw,
    feature_names=unsw_encoder.get_feature_names_out().tolist() + num_features,
    class_names=['Normal', 'Attack'],
    mode='classification',
    discretize_continuous=False
)

# Explain a sample prediction
sample_idx = 0
# Reshape the single sample to a 2D array for explain_instance
sample_to_explain = X_test_unsw[sample_idx].reshape(1, -1)

# The predict function for LIME should accept a 2D array (samples, features)
# and return the probability of each class. The model expects 3D input,
# so we reshape inside the predict function.
def lime_predict_fn(x):
    # Reshape the input to the model's expected 3D shape (samples, features, 1)
    x_3d = x.reshape(x.shape[0], x.shape[1], 1)
    # model.predict returns probabilities for the positive class (attack=1)
    # LIME expects probabilities for all classes [prob_normal, prob_attack]
    prob_attack = model.predict(x_3d)
    prob_normal = 1 - prob_attack
    return np.c_[prob_normal, prob_attack]


exp = explainer.explain_instance(
    sample_to_explain[0], # explain_instance expects a single sample (1D array)
    lime_predict_fn,
    num_features=10
)

# Show explanation
print("\n=== LIME EXPLANATION ===")
exp.show_in_notebook(show_table=True)

"""# Adversarial Training"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score

# FIXED FGSM ATTACK FUNCTION
def fgsm_attack(model, x, y, epsilon=0.1):
    """
    Fixed FGSM implementation with shape and type handling
    """
    # Convert to TensorFlow variables with consistent type
    x_tensor = tf.convert_to_tensor(x, dtype=tf.float32)
    y_tensor = tf.convert_to_tensor(y, dtype=tf.float32)

    # Compute min/max from the tensor itself (same dtype)
    x_min = tf.reduce_min(x_tensor)
    x_max = tf.reduce_max(x_tensor)

    with tf.GradientTape() as tape:
        tape.watch(x_tensor)
        prediction = model(x_tensor)

        # Ensure proper loss calculation with matching shapes
        if len(y_tensor.shape) == 1:
            y_tensor = tf.expand_dims(y_tensor, axis=-1)

        loss = tf.keras.losses.binary_crossentropy(y_tensor, prediction)

    # Calculate gradients
    gradient = tape.gradient(loss, x_tensor)

    # Create perturbation
    perturbation = epsilon * tf.sign(gradient)

    # Generate adversarial examples
    adv_x = x_tensor + perturbation
    adv_x = tf.clip_by_value(adv_x, x_min, x_max)

    return adv_x.numpy()

# FIXED ADVERSARIAL RETRAINING FUNCTION
def adversarial_retraining(model, X_train, y_train, epsilon=0.1, samples=10000, epochs=5):
    """
    Fixed adversarial retraining with shape handling
    """
    print("\nGenerating adversarial examples for training...")

    # Ensure float32 for training data
    X_train = X_train.astype(np.float32)

    # Generate adversarial examples in smaller batches to avoid InternalError
    batch_size_adv_gen = 512 # Reduced batch size for adversarial generation
    X_adv_list = []
    for i in range(0, min(samples, X_train.shape[0]), batch_size_adv_gen):
        X_train_batch = X_train[i:i + batch_size_adv_gen]
        y_train_batch = y_train[i:i + batch_size_adv_gen] # Assuming y_train is also batched accordingly, although not used in fgsm_attack's gradient calculation
        X_adv_batch = fgsm_attack(model, X_train_batch, y_train_batch, epsilon)
        X_adv_list.append(X_adv_batch)

    X_adv = np.concatenate(X_adv_list, axis=0)
    print(f"Generated {X_adv.shape[0]} adversarial examples.")

    # Combine with original data
    X_combined = np.concatenate([X_train[:X_adv.shape[0]], X_adv]) # Use the actual number of generated adv samples
    y_combined = np.concatenate([y_train[:X_adv.shape[0]], y_train[:X_adv.shape[0]]]) # Use the actual number of generated adv samples

    print(f"Created augmented dataset: {X_combined.shape[0]} samples")

    # Clone model architecture
    robust_model = tf.keras.models.clone_model(model)
    robust_model.compile(
        optimizer='adam',
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # Train on augmented dataset
    print("Starting adversarial training...")
    robust_model.fit(
        X_combined,
        y_combined,
        batch_size=256,
        epochs=epochs,
        verbose=1
    )

    return robust_model

# APPLY FIXED ADVERSARIAL TRAINING
# Configuration
ADV_EPSILON = 0.1         # Attack strength (10% of feature range)
ADV_SAMPLES = 20000       # Number of samples to augment (will process in batches internally)
ADV_EPOCHS = 5            # Retraining epochs

# Create robust model (WITH TYPE CONVERSION)
robust_model = adversarial_retraining(
    model,
    X_train_unsw_3d.astype(np.float32),  # Ensure float32
    y_train_unsw, # Using y_train_unsw, though only y_res_unsw was used in successful training. Need to clarify which y to use here. Assuming y_train_unsw for simplicity in fixing the current error.
    epsilon=ADV_EPSILON,
    samples=ADV_SAMPLES,
    epochs=ADV_EPOCHS
)
robust_model.save("/content/drive/MyDrive/Data_Anaylsis/model/cnn_lstm_UNSW-NB15_adversarial_model.h5")
print("‚úÖ Robust adversarial model saved as cnn_lstm_UNSW-NB15_adversarial_model.h5")


# FIXED ROBUSTNESS EVALUATION FUNCTION
def evaluate_robustness(model, X_test, y_test, epsilon=0.1):
    """
    Fixed robustness evaluation with type handling
    """
    results = []

    # Clean data performance
    y_pred_clean = (model.predict(X_test) > 0.5).astype(int)
    clean_acc = accuracy_score(y_test, y_pred_clean)
    results.append({'attack_strength': 0.0, 'accuracy': clean_acc, 'type': 'clean'})

    # Test different attack strengths
    for eps in [0.05, 0.1, 0.15, 0.2]:
        # Generate adversarial examples with proper typing
        # Process test data in smaller batches for adversarial generation as well
        batch_size_eval_adv_gen = 512
        X_adv_list = []
        for i in range(0, X_test.shape[0], batch_size_eval_adv_gen):
             X_test_batch = X_test[i:i + batch_size_eval_adv_gen]
             y_test_batch = y_test[i:i + batch_size_eval_adv_gen] # Assuming y_test is batched accordingly
             X_adv_batch = fgsm_attack(model, X_test_batch, y_test_batch, epsilon=eps)
             X_adv_list.append(X_adv_batch)
        X_adv = np.concatenate(X_adv_list, axis=0)


        # Evaluate
        y_pred_adv = (model.predict(X_adv) > 0.5).astype(int)
        adv_acc = accuracy_score(y_test, y_pred_adv)
        results.append({'attack_strength': eps, 'accuracy': adv_acc, 'type': 'adversarial'})

        print(f"Epsilon: {eps:.2f} \t Accuracy: {adv_acc:.4f}")

    return pd.DataFrame(results)

# RUN EVALUATION WITH TYPE SAFETY
# Evaluate original model vulnerability
print("\n=== ORIGINAL MODEL VULNERABILITY ===")
orig_results = evaluate_robustness(
    model,
    X_test_unsw_3d[:2000].astype(np.float32),
    y_test_unsw[:2000],
)

# Evaluate robust model
print("\n=== ROBUST MODEL VULNERABILITY ===")
robust_results = evaluate_robustness(
    robust_model,
    X_test_unsw_3d[:2000].astype(np.float32),
    y_test_unsw[:2000],
)

# Combine results
orig_results['model'] = 'Original'
robust_results['model'] = 'Robust'
combined_results = pd.concat([orig_results, robust_results])

# Visualize comparison
plt.figure(figsize=(10, 6))
sns.lineplot(
    x='attack_strength',
    y='accuracy',
    hue='model',
    style='type',
    markers=True,
    dashes=False,
    data=combined_results[combined_results['type'] == 'adversarial']
)
plt.axhline(
    y=combined_results[(combined_results['type'] == 'clean') &
                      (combined_results['model'] == 'Original')]['accuracy'].values[0],
    color='red',
    linestyle='--',
    label='Original Clean'
)
plt.axhline(
    y=combined_results[(combined_results['type'] == 'clean') &
                      (combined_results['model'] == 'Robust')]['accuracy'].values[0],
    color='blue',
    linestyle='--',
    label='Robust Clean'
)
plt.title('Adversarial Robustness Comparison')
plt.xlabel('Attack Strength (Epsilon)')
plt.ylabel('Accuracy')
plt.legend(title='Model')
plt.grid(True)
plt.show()
# Add this to the end of your training script after the preprocess_unsw() function

import pickle
import os

# Create a models directory if it doesn't exist
os.makedirs('/content/drive/MyDrive/Data_Anaylsis/model', exist_ok=True)

# Save the preprocessors
def save_preprocessors(encoder, scaler, num_features, base_path='/content/drive/MyDrive/Data_Anaylsis/model'):
    """Save all preprocessing components for deployment"""
    
    try:
        # Save the OneHotEncoder
        encoder_path = os.path.join(base_path, 'encoder.pkl')
        with open(encoder_path, 'wb') as f:
            pickle.dump(encoder, f)
        print(f"‚úÖ Encoder saved to: {encoder_path}")
        
        # Save the StandardScaler
        scaler_path = os.path.join(base_path, 'scaler.pkl')
        with open(scaler_path, 'wb') as f:
            pickle.dump(scaler, f)
        print(f"‚úÖ Scaler saved to: {scaler_path}")
        
        # Save the feature names for reference
        feature_info = {
            'num_features': num_features,
            'cat_features': ['PROTOCOL'],
            'feature_order': list(encoder.get_feature_names_out()) + num_features
        }
        
        feature_path = os.path.join(base_path, 'feature_info.pkl')
        with open(feature_path, 'wb') as f:
            pickle.dump(feature_info, f)
        print(f"‚úÖ Feature info saved to: {feature_path}")
        
        print("\nüéâ All preprocessors saved successfully!")
        print(f"Files saved in: {base_path}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error saving preprocessors: {str(e)}")
        return False

# Call the function with your existing preprocessors
success = save_preprocessors(unsw_encoder, unsw_scaler, num_features)

if success:
    print("\nüìã Preprocessor Summary:")
    print(f"- Encoder handles: {['PROTOCOL']}")
    print(f"- Scaler handles: {len(num_features)} numerical features")
    print(f"- Total features after preprocessing: {len(unsw_encoder.get_feature_names_out()) + len(num_features)}")
    print(f"- Input shape for model: ({len(unsw_encoder.get_feature_names_out()) + len(num_features)}, 1)")